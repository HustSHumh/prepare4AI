{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "b56dc23b-dc9f-4ede-948d-c9b55882725e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from odps import ODPS\n",
    "from odps.df import DataFrame\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import catboost as cb\n",
    "from tqdm import tqdm\n",
    "from pvlib import location\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "\n",
    "# 公共OSS AK\n",
    "bucket_name = 'sf-2023'\n",
    "oss_endpoint = 'http://oss-cn-guangzhou-nfdw-d01-a.pdcc-cloud-inc.cn'\n",
    "AK = 'wbr4Y7IjXopW7CWZ'\n",
    "AKS = 'reP1eCeahBC7U9w0i5rhQU9oGgS0NA'\n",
    "\n",
    "# 广西AK\n",
    "AK_GX = 'MBs3yHviVlKIY3gh'\n",
    "AKS_GX = 'wUvWZOnGTtWVVir65A3ogIfOKSkHIB'\n",
    "NAME = 'sf_2023_chenquanqi'\n",
    "endpoint = 'http://service.cn-guangzhou-nfdw-d01.odps.pdcc-cloud-inc.cn/api'\n",
    "\n",
    "\n",
    "oid_list = ['15481140756807681','15481140756873217','15481140756938753','15481140830863361','15481140766113793',\n",
    "            '15481140766179329','15481140766244865','15481140766310401','15481140757266433','15481140757725185',\n",
    "            '15481140757790721','15481140757004289','15481140757069825','15481140757135361','15481140757200897',\n",
    "            '15481140766375937','15481140766441473','15481140766507009','15481140766572545','15481137326915585',\n",
    "            '15481130476634115','15481130500882435','15481125255184390','15481129194225670','15481128900034564',\n",
    "            '15481128891252742','15481130821025794','15481130821156866','15481130901110786','15481131802034178']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "7ff4c0f6-b689-4208-b5a1-4d932fa05beb"
   },
   "outputs": [],
   "source": [
    "def pull_jiutian_wind(ybsj1, ybsj2):\n",
    "    o = ODPS(\n",
    "        AK_GX,\n",
    "        AKS_GX,\n",
    "        NAME,\n",
    "        endpoint\n",
    "    )\n",
    "    run_start_time = datetime.datetime.now()\n",
    "    \n",
    "    start_time = str(ybsj1)+ ' 00:00:00'\n",
    "    end_time = str(ybsj2) + ' 23:45:00'\n",
    "    print('开始读取玖天风向风速数据', datetime.datetime.now() - run_start_time)\n",
    "    sql = '''select fbsj, ybsj, latitude, longitude, ten_meter_wind_speed, one_hundred_wind_speed, ten_meter_wind_direction, one_hundred_meter_wind_direction from sf_2023_pw.t_jiutian_gridding_data t \n",
    "    where t.fbsj >= \"{}\" and t.fbsj <= \"{}\"'''.format(start_time, end_time)\n",
    "    querry_job = o.execute_sql(sql)\n",
    "    result = querry_job.open_reader()\n",
    "    df = result.to_pandas()\n",
    "    print('读取玖天风向风速数据', datetime.datetime.now() - run_start_time)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pull_jiutian_radiation(ybsj1, ybsj2):\n",
    "    o = ODPS(\n",
    "        AK_GX,\n",
    "        AKS_GX,\n",
    "        NAME,\n",
    "        endpoint\n",
    "    )\n",
    "    run_start_time = datetime.datetime.now()\n",
    "    \n",
    "    start_time = str(ybsj1)+ ' 00:00:00'\n",
    "    end_time = str(ybsj2) + ' 23:45:00'\n",
    "    sql = '''select fbsj, ybsj, latitude, longitude, total_radiation from sf_2023_pw.t_jiutian_gridding_data t \n",
    "    where t.fbsj >= \"{}\" and t.fbsj <= \"{}\"'''.format(start_time, end_time)\n",
    "    querry_job = o.execute_sql(sql)\n",
    "    result = querry_job.open_reader()\n",
    "    df = result.to_pandas()\n",
    "    print('读取玖天辐照度数据', datetime.datetime.now() - run_start_time)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pull_qxj_weather_data(table_name, ybsj1, ybsj2):\n",
    "    o = ODPS(\n",
    "        AK_GX,\n",
    "        AKS_GX,\n",
    "        NAME,\n",
    "        endpoint\n",
    "    )\n",
    "    \n",
    "    run_start_time = datetime.datetime.now()\n",
    "    \n",
    "    start_time = str(ybsj1) + ' 00:00:00'\n",
    "    end_time = str(ybsj2) + ' 23:45:00'\n",
    "    sql = '''select * from sf_2023_pw.{} t \n",
    "    where t.zlsc >= \"{}\" and t.zlsc <= \"{}\"'''.format(str(table_name), str(start_time), end_time)\n",
    "    querry_job = o.execute_sql(sql)\n",
    "    result = querry_job.open_reader()\n",
    "    df = result.to_pandas()\n",
    "    df.sort_values(by=['zlsc', 'qxjzh'], inplace=True)\n",
    "    print('读取气象局风电气象数据', datetime.datetime.now() - run_start_time)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pull_qxj_radiation_data(table_name, ybsj1, ybsj2):\n",
    "    o = ODPS(\n",
    "        AK_GX,\n",
    "        AKS_GX,\n",
    "        NAME,\n",
    "        endpoint\n",
    "    )\n",
    "    \n",
    "    run_start_time = datetime.datetime.now()\n",
    "    \n",
    "    start_time = str(ybsj1) + ' 00:00:00'\n",
    "    end_time = str(ybsj2) + ' 23:45:00'\n",
    "    sql = '''select * from sf_2023_pw.{} t \n",
    "    where t.zlsc >= \"{}\" and t.zlsc <= \"{}\"'''.format(str(table_name), str(start_time), end_time)\n",
    "    querry_job = o.execute_sql(sql)\n",
    "    result = querry_job.open_reader()\n",
    "    df = result.to_pandas()\n",
    "    df.sort_values(by=['zlsc', 'qxjzh'], inplace=True)\n",
    "    print('读取气象局光伏气象数据', datetime.datetime.now() - run_start_time)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pull_power_data(start_date, end_date):\n",
    "    # update_all = True 时全量更新数据\n",
    "    o = ODPS(\n",
    "            AK_GX,\n",
    "            AKS_GX,\n",
    "            NAME,\n",
    "            endpoint\n",
    "        )\n",
    "    run_start_time = datetime.datetime.now()\n",
    "    start_time = str(start_date)+ ' 00:00:00'\n",
    "    end_time = str(end_date) + ' 23:45:00'\n",
    "\n",
    "    sql = '''select * from sf_2023_pw.t_electricity t \n",
    "    where t.power_time >= \"{}\" and t.power_time <= \"{}\"'''.format(start_time, end_time)\n",
    "    querry_job = o.execute_sql(sql)\n",
    "    result = querry_job.open_reader()\n",
    "    df = result.to_pandas()\n",
    "    print('读取发电功率数据', datetime.datetime.now() - run_start_time)\n",
    "    return df\n",
    "\n",
    "def update_capacity():\n",
    "    o = ODPS(\n",
    "        AK_GX,\n",
    "        AKS_GX,\n",
    "        NAME,\n",
    "        endpoint\n",
    "    )\n",
    "    sql = '''select oid, data_name, acc_month, capacity from sf_2023_pw.td_capacity t '''\n",
    "    querry_job = o.execute_sql(sql)\n",
    "    result = querry_job.open_reader()\n",
    "    df = result.to_pandas()\n",
    "    df.sort_values('acc_month', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['oid'] = df['oid'].astype(str)\n",
    "    df['capacity'] = df['capacity'].astype(float)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "70e78e72-01c1-416a-9801-3b66867d6ecb"
   },
   "outputs": [],
   "source": [
    "def create_dir_if_not_exist(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    return dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "uuid": "d752f13b-b89f-49fb-b0a9-8b6c9a26bb06"
   },
   "outputs": [],
   "source": [
    "def prepare_power(start_date, end_date, oid_list):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/power/{}.p'.format(str(date.date())))\n",
    "        df_date = df_date[df_date['oid'].isin(oid_list)]\n",
    "        df_date = df_date[['power_time', 'oid', 'type', 'power']]\n",
    "        df_date.drop_duplicates(subset=['power_time', 'oid', 'type'], keep='last', inplace=True)\n",
    "        df_date.set_index('power_time', inplace=True)\n",
    "        df_date['oid'] = df_date['oid'].astype(str)\n",
    "        df_date['type'] = df_date['type'].astype(str)\n",
    "        df_date['power'] = df_date['power'].astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date = df_date.tz_localize('Asia/Shanghai').sort_index()\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_qxj_weather_data(start_date, end_date):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/qxj_weather/{}.p'.format(str(date.date())))\n",
    "        df_date = df_date[['zlsc', 'wd', 'jd', 'hbgd', 'fx2fz', 'pjfs2fz', 'fx10fz', 'pjfs10fz']]\n",
    "        df_date.drop_duplicates(subset=['zlsc', 'wd', 'jd', 'hbgd'], keep='last', inplace=True)\n",
    "        df_date.set_index('zlsc', inplace=True)\n",
    "        df_date = df_date.astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date['fx2fz'] = df_date['fx2fz'].apply(lambda x: x if x < 361 else np.nan).interpolate(limit=1)\n",
    "        df_date['fx10fz'] = df_date['fx10fz'].apply(lambda x: x if x < 361 else np.nan).interpolate(limit=1)\n",
    "        df_date['pjfs2fz'] = df_date['pjfs2fz'].apply(lambda x: x if x < 99 else np.nan).interpolate(limit=1)\n",
    "        df_date['pjfs10fz'] = df_date['pjfs10fz'].apply(lambda x: x if x < 99 else np.nan).interpolate(limit=1)\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    df = df.tz_localize('Asia/Shanghai').sort_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_qxj_radi_data(start_date, end_date):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/qxj_radiation/{}.p'.format(str(date.date())))\n",
    "        df_date = df_date[['zlsc', 'wd', 'jd', 'hbgd', 'zfzd']]\n",
    "        df_date.drop_duplicates(subset=['zlsc', 'wd', 'jd', 'hbgd'], keep='last', inplace=True)\n",
    "        df_date.set_index('zlsc', inplace=True)\n",
    "        df_date = df_date.astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date['zfzd'] = df_date['zfzd'].apply(lambda x: x if x < 2999 else np.nan).interpolate(limit=1)\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    df = df.tz_localize('Asia/Shanghai').sort_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_jiutian_wind_data(start_date, end_date):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/jiutian_wind/{}.p'.format(str(date.date())))\n",
    "        mask = ((df_date['ybsj'] - df_date['fbsj']) > datetime.timedelta(hours=21, minutes=45)) & \\\n",
    "        ((df_date['ybsj'] - df_date['fbsj']) < datetime.timedelta(hours=46))\n",
    "        df_date = df_date[mask]\n",
    "        df_date.drop_duplicates(subset=['ybsj', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "        df_date.drop('fbsj', axis=1, inplace=True)\n",
    "        df_date.set_index('ybsj', inplace=True)\n",
    "        df_date = df_date.astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date['ten_meter_wind_speed'] = df_date['ten_meter_wind_speed'].apply(lambda x: x if x < 99 else np.nan).interpolate(limit=1)\n",
    "        df_date['one_hundred_wind_speed'] = df_date['one_hundred_wind_speed'].apply(lambda x: x if x < 99 else np.nan).interpolate(limit=1)\n",
    "        df_date['ten_meter_wind_direction'] = df_date['ten_meter_wind_direction'].apply(lambda x: x if x < 361 else np.nan).interpolate(limit=1)\n",
    "        df_date['one_hundred_meter_wind_direction'] = df_date['one_hundred_meter_wind_direction'].apply(lambda x: x if x < 361 else np.nan).interpolate(limit=1)\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    df = df.tz_localize('Asia/Shanghai').sort_index()\n",
    "    return df\n",
    "\n",
    "def get_jiutian_radi_data(start_date, end_date):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/jiutian_radiation/{}.p'.format(str(date.date())))\n",
    "        mask = ((df_date['ybsj'] - df_date['fbsj']) > datetime.timedelta(hours=21, minutes=45)) & \\\n",
    "        ((df_date['ybsj'] - df_date['fbsj']) < datetime.timedelta(hours=46))\n",
    "        df_date = df_date[mask]\n",
    "        df_date.drop_duplicates(subset=['ybsj', 'latitude', 'longitude'], keep='last', inplace=True)\n",
    "        df_date.drop('fbsj', axis=1, inplace=True)\n",
    "        df_date.set_index('ybsj', inplace=True)\n",
    "        df_date = df_date.astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date['total_radiation'].astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date['total_radiation'] = df_date['total_radiation'].apply(lambda x: x if x < 2999 else np.nan).interpolate(limit=1)\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    df = df.tz_localize('Asia/Shanghai').sort_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "uuid": "47f6beb7-9ffe-4c1e-9e2a-a1c948cbda4d"
   },
   "outputs": [],
   "source": [
    "def filter_jiutian_station(df_points_1, df_points_2, k, flag='jiutian'):\n",
    "    start_time = datetime.datetime.now()\n",
    "    df_points_1.reset_index(drop=False, inplace=True)\n",
    "    df_points_2.reset_index(drop=False, inplace=True)\n",
    "    power_time = 'zlsc'\n",
    "    jd = 'jd'\n",
    "    wd = 'wd'\n",
    "    if flag == 'jiutian':\n",
    "        jd = 'longitude'\n",
    "        wd = 'latitude'\n",
    "        power_time = 'ybsj'\n",
    "    df_loc_1 = df_points_1.loc[:, ['jd', 'wd']].drop_duplicates() # dataframe   (n1, 2)\n",
    "    df_loc_2 = df_points_2.loc[:, [jd, wd]].drop_duplicates()  # dataframe (n_station, 2)\n",
    "    df_loc_2.reset_index(drop=True, inplace=True)\n",
    "    df_loc_1.reset_index(drop=True, inplace=True)\n",
    "    # KD树只返回相对index\n",
    "    n_time = df_points_2[power_time].unique().shape[0]\n",
    "#     print('开始建树', datetime.datetime.now() - start_time)\n",
    "    Tree = KDTree(df_loc_2)\n",
    "    dist, ind = Tree.query(df_loc_1, k) # ind: n1*5\n",
    "#     print('建树完成', datetime.datetime.now() - start_time)\n",
    "    df_jiutian_dict = {}\n",
    "    for idx in ind:\n",
    "        jd_tmp_list = df_loc_2.loc[idx, jd].tolist()\n",
    "        wd_tmp_list = df_loc_2.loc[idx, wd].tolist()\n",
    "        for jd_, wd_ in zip(jd_tmp_list, wd_tmp_list): \n",
    "            df_jiutian_dict[(jd_, wd_)] = df_jiutian_dict.get((jd_, wd_), 0) + 1\n",
    "    return df_jiutian_dict\n",
    "\n",
    "def simulate_curve3(df_points_1, df_points_2, k, feature_list, flag='jiutian'):\n",
    "    df_points_2.reset_index(drop=False, inplace=True)\n",
    "    start_time = datetime.datetime.now()\n",
    "    power_time = 'zlsc'\n",
    "    jd = 'jd'\n",
    "    wd = 'wd'\n",
    "    if flag == 'jiutian':\n",
    "        jd = 'longitude'\n",
    "        wd = 'latitude'\n",
    "        power_time = 'ybsj'\n",
    "    df_loc_1 = df_points_1.loc[:, ['jd', 'wd']].drop_duplicates() # dataframe   (n1, 2)\n",
    "    df_loc_2 = df_points_2.loc[:, [jd, wd]].drop_duplicates()  # dataframe (n_station, 2)\n",
    "    df_loc_2.reset_index(drop=True, inplace=True)\n",
    "    df_loc_1.reset_index(drop=True, inplace=True)\n",
    "    if power_time not in feature_list:\n",
    "        feature_list.append(power_time)\n",
    "    # KD树只返回相对index\n",
    "    n_time = df_points_2[power_time].unique().shape[0]\n",
    "    Tree = KDTree(df_loc_2)\n",
    "    dist, ind = Tree.query(df_loc_1, k) # ind: n1*5\n",
    "#     convert dataframe to dict\n",
    "    df_points_dict2 = {}\n",
    "    for idx, val in df_loc_2.iterrows():\n",
    "        key = (val[jd], val[wd])\n",
    "        data = df_points_2.loc[df_points_2['loc']==key, feature_list]\n",
    "        data.drop_duplicates(subset=[power_time], inplace=True)\n",
    "        df_points_dict2[key] = data\n",
    "    \n",
    "    station_list = []\n",
    "    for idx in ind: # iterate n1 idx.shape = (5,)\n",
    "        jd_tmp_list = df_loc_2.loc[idx, jd].tolist()\n",
    "        wd_tmp_list = df_loc_2.loc[idx, wd].tolist()\n",
    "        convert_tmp = None\n",
    "        for jd_, wd_ in zip(jd_tmp_list, wd_tmp_list): #iterate k\n",
    "            if convert_tmp is None:\n",
    "                convert_tmp = (df_points_dict2[(jd_, wd_)]).set_index(power_time)\n",
    "            else:\n",
    "                convert_tmp += (df_points_dict2[(jd_, wd_)]).set_index(power_time)\n",
    "        convert_tmp /= k\n",
    "        station_list.append(convert_tmp)\n",
    "    df_final = pd.DataFrame()\n",
    "    for idx, row in df_loc_1.iterrows():\n",
    "        df_tmp = pd.DataFrame(\n",
    "            {\n",
    "                'power_time' : df_points_2[power_time].unique(),\n",
    "                'jd' : [row['jd']] * n_time,\n",
    "                'wd' : [row['wd']] * n_time,\n",
    "            }\n",
    "        )\n",
    "        df_tmp = df_tmp.set_index('power_time')\n",
    "        df_tmp = pd.concat([df_tmp, station_list[idx]], axis=1)\n",
    "        df_final = pd.concat([df_final, df_tmp], axis = 0)\n",
    "        \n",
    "    return df_final\n",
    "\n",
    "\n",
    "def prepare_jiutian2qxj_data():\n",
    "#     today = datetime.date.today() - datetime.timedelta(days=1)\n",
    "    today = datetime.date.today()\n",
    "    his_end_date = str(today)\n",
    "    pred_date = str(today + datetime.timedelta(days=1))\n",
    "    save_dirpath = '~/workspace/data/jiutian2qxj'\n",
    "    qxj_weather_feature = ['fx2fz', 'pjfs2fz', 'fx10fz', 'pjfs10fz']\n",
    "    qxj_radiation_feature = ['zfzd']\n",
    "    jiutian_wind_feature  = ['ten_meter_wind_speed', 'one_hundred_wind_speed', 'ten_meter_wind_direction', 'one_hundred_meter_wind_direction']\n",
    "    jiutian_radi_feature = ['total_radiation']\n",
    "    \n",
    "    df_qxj_weather_data = get_qxj_weather_data(his_end_date, his_end_date)\n",
    "#     print('完成获取气象局风电气象数据，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    df_qxj_radiation_data = get_qxj_radi_data(his_end_date, his_end_date)\n",
    "#     print('完成获取气象局光伏气象数据，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    \n",
    "    df_jiutian_wind_data = get_jiutian_wind_data(his_end_date, his_end_date)\n",
    "    df_jiutian_wind_data['loc'] = df_jiutian_wind_data[['longitude', 'latitude']].apply(tuple, axis=1)\n",
    "    df_jiutian_radi_data = get_jiutian_radi_data(his_end_date, his_end_date)\n",
    "    df_jiutian_radi_data['loc'] = df_jiutian_radi_data[['longitude', 'latitude']].apply(tuple, axis=1)\n",
    "    \n",
    "    df_jiutian_filter = get_jiutian_wind_data(his_end_date, his_end_date)\n",
    "#     print('完成获取玖天预测气象数据，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    \n",
    "    # 筛选出需要用到的玖天气象站\n",
    "    dict_jiutian_wind = filter_jiutian_station(df_qxj_weather_data, df_jiutian_filter, 5)\n",
    "    dict_jiutian_radi = filter_jiutian_station(df_qxj_radiation_data, df_jiutian_filter, 5)\n",
    "    #KD tree拟合出气象局的数据\n",
    "    df_jiutian_wind_data = df_jiutian_wind_data.loc[df_jiutian_wind_data['loc'].isin(dict_jiutian_wind)]\n",
    "    df_jiutian_radi_data = df_jiutian_radi_data.loc[df_jiutian_radi_data['loc'].isin(dict_jiutian_radi)]\n",
    "\n",
    "\n",
    "    jiutian2qxj_wind = simulate_curve3(df_qxj_weather_data, df_jiutian_wind_data,5, jiutian_wind_feature)\n",
    "    jiutian2qxj_radi = simulate_curve3(df_qxj_radiation_data, df_jiutian_radi_data,5, jiutian_radi_feature)\n",
    "    \n",
    "    jiutian2qxj_wind.to_pickle(os.path.join(save_dirpath, '{}wind.p'.format(str(today+datetime.timedelta(days=1)))))\n",
    "    jiutian2qxj_radi.to_pickle(os.path.join(save_dirpath, '{}radi.p'.format(str(today+datetime.timedelta(days=1)))))\n",
    "    \n",
    "    return jiutian2qxj_wind,jiutian2qxj_radi\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "uuid": "dc8a9648-325c-4423-af6c-d1f9c5183209"
   },
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    current_date = str(datetime.date.today())\n",
    "    prev_date = str(datetime.date.today() - datetime.timedelta(days=1))\n",
    "\n",
    "    _df = pull_jiutian_wind(current_date, current_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/jiutian_wind/{}.p'.format(current_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_jiutian_radiation(current_date, current_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/jiutian_radiation/{}.p'.format(current_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_qxj_weather_data('t_qxj_country_weather2023', current_date, current_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/qxj_weather/{}.p'.format(current_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_qxj_weather_data('t_qxj_country_weather2023', prev_date, prev_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/qxj_weather/{}.p'.format(prev_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_qxj_radiation_data('t_qxj_country_radiation', current_date, current_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/qxj_radiation/{}.p'.format(current_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_qxj_radiation_data('t_qxj_country_radiation', prev_date, prev_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/qxj_radiation/{}.p'.format(prev_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_power_data(current_date, current_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/power/{}.p'.format(current_date))\n",
    "    del _df\n",
    "\n",
    "    _df = pull_power_data(prev_date, prev_date)\n",
    "    _df.to_pickle('/home/admin/workspace/data/power/{}.p'.format(prev_date))\n",
    "    del _df\n",
    "    \n",
    "    _df = update_capacity()\n",
    "    _df.to_pickle('/home/admin/workspace/data/oid/newest.p')\n",
    "    _df.to_pickle('/home/admin/workspace/data/oid/{}.p'.format(prev_date))\n",
    "    del _df\n",
    "    \n",
    "    gc.collect()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "uuid": "0d14ba12-22dd-4d61-b268-b7ee81ccae00"
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    res_dirpath = '/home/admin/workspace/results_v1/{}'.format(str(datetime.date.today() + datetime.timedelta(days=1)))\n",
    "#     res_dirpath = '~/workspace/results_v1/{}'.format(str(datetime.date.today()))\n",
    "    create_dir_if_not_exist(res_dirpath)\n",
    "    \n",
    "#     power_start_date = str(datetime.date.today() - datetime.timedelta(days=121))\n",
    "    \n",
    "#     power_end_date = str(datetime.date.today() - datetime.timedelta(days=1))\n",
    "    power_start_date = str(datetime.date.today() - datetime.timedelta(days=120))\n",
    "    power_end_date = str(datetime.date.today())\n",
    "    df_power = prepare_power(power_start_date, power_end_date, oid_list)\n",
    "    df_power.to_pickle(os.path.join(res_dirpath, 'df_power.p'))\n",
    "    \n",
    "    jiutian2qxj_wind,jiutian2qxj_radi = prepare_jiutian2qxj_data()\n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "69c2f5a0-f02f-4a36-a814-c8079436e2bd"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    get_all_data()\n",
    "    prepare_data()\n",
    "    return \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "uuid": "4e3c3b1d-349d-451f-8700-d02524d19574"
   },
   "outputs": [],
   "source": [
    "prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "uuid": "8d8246aa-a308-4a3b-a240-1d97e753b9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'~'   baseline.py   get_data.ipynb   get_data.py   predict.ipynb   predict.py\n"
     ]
    }
   ],
   "source": [
    "!cd /home/admin/workspace/\n",
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "789a19fa-ab3a-4abd-af50-1f267135c983"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "af6651ef-be63-4e6c-b6d0-768eec3aa7ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "4c03f026-ed77-4b28-9b2d-ae2cc27fd599"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
