{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ca6bf6c9-7c91-457e-8b73-697feeca8329"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from odps import ODPS\n",
    "from odps.df import DataFrame\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import catboost as cb\n",
    "from tqdm import tqdm\n",
    "from pvlib import location\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "# 公共OSS AK\n",
    "bucket_name = 'sf-2023'\n",
    "oss_endpoint = 'http://oss-cn-guangzhou-nfdw-d01-a.pdcc-cloud-inc.cn'\n",
    "AK = 'wbr4Y7IjXopW7CWZ'\n",
    "AKS = 'reP1eCeahBC7U9w0i5rhQU9oGgS0NA'\n",
    "\n",
    "# 广西AK\n",
    "AK_GX = 'MBs3yHviVlKIY3gh'\n",
    "AKS_GX = 'wUvWZOnGTtWVVir65A3ogIfOKSkHIB'\n",
    "NAME = 'sf_2023_chenquanqi'\n",
    "endpoint = 'http://service.cn-guangzhou-nfdw-d01.odps.pdcc-cloud-inc.cn/api'\n",
    "\n",
    "\n",
    "oid_list = ['15481140756807681','15481140756873217','15481140756938753','15481140830863361','15481140766113793',\n",
    "            '15481140766179329','15481140766244865','15481140766310401','15481140757266433','15481140757725185',\n",
    "            '15481140757790721','15481140757004289','15481140757069825','15481140757135361','15481140757200897',\n",
    "            '15481140766375937','15481140766441473','15481140766507009','15481140766572545','15481137326915585',\n",
    "            '15481130476634115','15481130500882435','15481125255184390','15481129194225670','15481128900034564',\n",
    "            '15481128891252742','15481130821025794','15481130821156866','15481130901110786','15481131802034178']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "50fdfc82-1b46-40c1-a827-c6be7acf5ce2"
   },
   "outputs": [],
   "source": [
    "def get_power_station():\n",
    "    df = pd.read_pickle('~/workspace/data/station/20230821.p')\n",
    "    return df\n",
    "\n",
    "def get_oid_capacity():\n",
    "    df = pd.read_pickle('~/workspace/data/oid/newest.p')\n",
    "    return df\n",
    "\n",
    "def get_power_data(start_date, end_date, oid_list):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/power/{}.p'.format(str(date.date())))\n",
    "        df_date = df_date[df_date['oid'].isin(oid_list)]\n",
    "        df_date = df_date[['power_time', 'oid', 'type', 'power']]\n",
    "        df_date.drop_duplicates(subset=['power_time', 'oid', 'type'], keep='last', inplace=True)\n",
    "        df_date.set_index('power_time', inplace=True)\n",
    "        df_date['oid'] = df_date['oid'].astype(str)\n",
    "        df_date['type'] = df_date['type'].astype(str)\n",
    "        df_date['power'] = df_date['power'].astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date = df_date.tz_localize('Asia/Shanghai').sort_index()\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_power(start_date, end_date, oid_list):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/power/{}.p'.format(str(date.date())))\n",
    "        df_date = df_date[df_date['oid'].isin(oid_list)]\n",
    "        df_date = df_date[['power_time', 'oid', 'type', 'power']]\n",
    "        df_date.drop_duplicates(subset=['power_time', 'oid', 'type'], keep='last', inplace=True)\n",
    "        df_date.set_index('power_time', inplace=True)\n",
    "        df_date['oid'] = df_date['oid'].astype(str)\n",
    "        df_date['type'] = df_date['type'].astype(str)\n",
    "        df_date['power'] = df_date['power'].astype(float).apply(lambda x: round(x, 8))\n",
    "        df_date = df_date.tz_localize('Asia/Shanghai').sort_index()\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    return df\n",
    "\n",
    "def get_jiutian2qxj_data(start_date, end_date, flag):\n",
    "    df_ls = []\n",
    "    for date in tqdm(pd.date_range(start_date, end_date, freq='D')):\n",
    "        df_date = pd.read_pickle('~/workspace/data/jiutian2qxj/{}.p'.format(str(date.date())+ flag))\n",
    "        df_ls.append(df_date)\n",
    "    df = pd.concat(df_ls)\n",
    "    df = df.sort_index()\n",
    "    return df    \n",
    "\n",
    "\n",
    "\n",
    "def get_clearsky(dt_idx, lat, lon, alt=0):\n",
    "    site = location.Location(lat, lon, altitude=alt, tz='Asia/Shanghai')\n",
    "    df_clearsky = site.get_clearsky(dt_idx, model='ineichen')\n",
    "    return df_clearsky\n",
    "\n",
    "\n",
    "\n",
    "def create_loc_feature(df_jiutian2qxj_data, feature_list):\n",
    "    align_pred_ls = []\n",
    "    df_jiutian2qxj_data['loc'] = df_jiutian2qxj_data[['jd', 'wd']].apply(tuple, axis=1)\n",
    "    for loc in df_jiutian2qxj_data['loc'].unique():\n",
    "        df_pred_ = pd.DataFrame(index=df_jiutian2qxj_data.index.unique())\n",
    "        df_pred_ = df_jiutian2qxj_data.loc[df_jiutian2qxj_data['loc'] == loc, feature_list]\n",
    "        df_pred_.columns = ['{}_{}_{}'.format(feature, loc[0], loc[1]) for feature in feature_list]\n",
    "        align_pred_ls.append(df_pred_)\n",
    "    df_pred_aligned = pd.concat(align_pred_ls, axis=1).interpolate(limit=3)\n",
    "    return df_pred_aligned.applymap(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "def post_process_oid(df_pred):\n",
    "    df_station = get_oid_capacity()\n",
    "    for oid,df_pred_ in df_pred.groupby('oid'):\n",
    "        station_r1 = df_station.loc[df_station['oid'] == oid,'capacity'].values[0] * 0.1\n",
    "        df_pred.loc[df_pred['oid'] == oid,'y_pred'] = df_pred_['y_pred'].apply(lambda x: x if x >= station_r1 else station_r1)\n",
    "    return df_pred\n",
    "\n",
    "def create_dir_if_not_exist(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    return dirpath\n",
    "\n",
    "def send_results(df_pred):\n",
    "    df_res = pd.DataFrame()\n",
    "    df_res['oid'] = df_pred['oid'].values\n",
    "    df_res['sjrq'] = [datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')] * 2880\n",
    "    df_res['ycrq'] = df_pred.index.tz_localize(None).to_list()\n",
    "    df_res['ycz'] = df_pred['y_pred'].values\n",
    "    df_res['rksj'] = [datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')] * 2880\n",
    "    df_res['dwmc'] = ['sf_2023_chenquanqi'] * 2880 \n",
    "    o = ODPS(\n",
    "        AK_GX,\n",
    "        AKS_GX,\n",
    "        NAME,\n",
    "        endpoint\n",
    "        )\n",
    "    # 入库\n",
    "    DataFrame(df_res).persist('t_power_forecast', odps=o)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "390a0165-c2cb-4872-a46b-8536b2c609b5"
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "\n",
    "    pred_date = datetime.date.today() + datetime.timedelta(days=1)\n",
    "    pred_today = pred_date - datetime.timedelta(days=1)\n",
    "    his_start_date = '2023-08-02'\n",
    "    his_end_date = str(pred_date - datetime.timedelta(days=1))\n",
    "    res_dirpath = 'results_v1/{}'.format(pred_date)\n",
    "    create_dir_if_not_exist(res_dirpath)\n",
    "\n",
    "    # 获取8月2日至今的数据\n",
    "    df_power_data = get_power_data(his_start_date, his_end_date, oid_list)\n",
    "#     print('完成获取OID历史功率数据，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    # df_qxj_weather_data = get_qxj_weather_data(his_end_date, his_end_date)\n",
    "    #     print('完成获取气象局风电气象数据，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    # df_qxj_radiation_data = get_qxj_radi_data(his_end_date, his_end_date)\n",
    "    df_jiutian2qxj_wind_data = get_jiutian2qxj_data(his_start_date, pred_date, 'wind')\n",
    "    df_jiutian2qxj_radi_data = get_jiutian2qxj_data(his_start_date, pred_date, 'radi')\n",
    "#     print('完成获取玖天数据，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    df_power = pd.read_pickle(os.path.join(res_dirpath, 'df_power.p'))\n",
    "\n",
    "    df_wind_align = create_loc_feature(df_jiutian2qxj_wind_data, \n",
    "                                       ['ten_meter_wind_speed', 'one_hundred_wind_speed', 'ten_meter_wind_direction', 'one_hundred_meter_wind_direction'])\n",
    "    df_wind_align.to_pickle(os.path.join(res_dirpath, 'df_wind_align.p'))\n",
    "#     print('完成风力特征训练，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "    df_radi_align = create_loc_feature(df_jiutian2qxj_radi_data, ['total_radiation'])\n",
    "    df_radi_align.to_pickle(os.path.join(res_dirpath, 'df_radi_align.p'))\n",
    "#     print('完成光伏特征训练，共耗时 ', datetime.datetime.now() - now_time, 's')\n",
    "\n",
    "    power_train_start = '2023-08-02' + ' 00:00'\n",
    "    power_train_end = str(pred_today - datetime.timedelta(days=1)) + ' 23:45'\n",
    "    # power_val_start = str(datetime.date.today() - datetime.timedelta(days=6)) + ' 00:00'\n",
    "    # power_val_end = str(datetime.date.today() - datetime.timedelta(days=1)) + ' 23:45'\n",
    "    power_pred_start = str(pred_today + datetime.timedelta(days=1)) + ' 00:00'\n",
    "    power_pred_end = str(pred_today + datetime.timedelta(days=1)) + ' 23:45'\n",
    "\n",
    "    train_data_ls = []\n",
    "    # val_data_ls = []\n",
    "    pred_data_ls = []\n",
    "    for oid, df_oid in tqdm(df_power.groupby('oid')):\n",
    "        data_ = pd.concat([df_oid, df_wind_align, df_radi_align], axis=1)\n",
    "        data_['oid'] = data_['oid'].ffill()\n",
    "        data_['type'] = data_['type'].ffill()\n",
    "        data_['oid'] = data_['oid'].astype(str)\n",
    "        data_['type'] = data_['type'].astype(str)\n",
    "        data_['hour'] = data_.index.hour\n",
    "        data_['minute'] = data_.index.minute\n",
    "        data_['hour_sin'] = np.sin(data_['hour'] / 23 * 2 * np.pi)\n",
    "        data_['hour_cos'] = np.cos(data_['hour'] / 23 * 2 * np.pi)\n",
    "        data_['minute_sin'] = np.sin(data_['minute'] / 59 * 2 * np.pi)\n",
    "        data_['minute_cos'] = np.cos(data_['minute'] / 59 * 2 * np.pi)\n",
    "        data_['time_96'] = data_.apply(lambda x: (x['hour'] * 60 + x['minute']) / 15 + 1, axis=1)\n",
    "        data_['hour'] = data_['hour'].astype(str)\n",
    "        data_['minute'] = data_['minute'].astype(str)\n",
    "        data_['num_samples'] = list(range(len(data_)))\n",
    "        train_data_ = data_.loc[power_train_start:power_train_end]\n",
    "    #     val_data_ = data_.loc[power_val_start:power_val_end]\n",
    "        pred_data_ = data_.loc[power_pred_start:power_pred_end]\n",
    "        train_data_ls.append(train_data_)\n",
    "    #     val_data_ls.append(val_data_)\n",
    "        pred_data_ls.append(pred_data_)\n",
    "    train_data = pd.concat(train_data_ls)\n",
    "    # val_data = pd.concat(val_data_ls)\n",
    "    pred_data = pd.concat(pred_data_ls)\n",
    "    X_train, y_train = train_data.loc[:, [i for i in train_data if i != 'power']], train_data['power']\n",
    "    # X_val, y_val = val_data.loc[:, [i for i in val_data if i != 'power']], val_data['power']\n",
    "    X_pred = pred_data.loc[:, [i for i in pred_data if i != 'power']]\n",
    "    train_nan_mask = y_train.isna().values\n",
    "    X_train = X_train[~train_nan_mask]\n",
    "    y_train = y_train[~train_nan_mask]\n",
    "    print('Start training...')\n",
    "    num_iterations = 3000\n",
    "    model = cb.CatBoostRegressor(iterations=num_iterations, loss_function='MAE', random_state=0, verbose=True, cat_features=['oid', 'type', 'hour', 'minute'])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_pred)\n",
    "    df_pred = X_pred.loc[:, ['oid', 'type']].copy()\n",
    "    df_pred['y_pred'] = y_pred\n",
    "    #post process\n",
    "    df_pred = post_process_oid(df_pred)\n",
    "    df_pred.to_pickle(os.path.join(res_dirpath, 'df_pred.p'))\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "3b17b822-b056-472f-ac56-404c38a58190"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    df_pred = predict()\n",
    "    send_results(df_pred)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "c992d233-f2be-4313-acee-9e0ecc7ed43f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "c3f41ea2-6f51-4b7c-93ad-ca225da5103a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "0f84ece6-a68c-4487-8e66-7a90a29e91b0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "bb221461-7af2-49d6-9862-27214f073d22"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ea738e9c-ace1-434f-bc95-5f32a7bdc29d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b15ebb1c-dc16-4dad-a3c8-ea307a42be37"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
